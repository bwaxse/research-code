{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENOTYPE EXTRACTION\n",
    "\n",
    "This notebook demonstrates how to extract genotypes for specific genetic variants across all participants from the All of Us Researcher Workbench.\n",
    "\n",
    "## WORKFLOW OVERVIEW:\n",
    "1. Set up environment and utility functions\n",
    "2. Configure paths and database connections\n",
    "3. Load and explore genomic data using Hail\n",
    "4. Extract genotypes for one or more specified variants\n",
    "5. Create a genotype matrix (participants √ó variants)\n",
    "6. (Optional) Add clinical/demographic data\n",
    "\n",
    "## KEY FEATURES:\n",
    "- Extract genotypes for **multiple variants simultaneously**\n",
    "- Creates a wide-format DataFrame with one column per variant\n",
    "- Each column shows actual genotypes (0/0, 0/1, 1/1) for all participants\n",
    "- Handles multi-allelic sites automatically\n",
    "\n",
    "## LEARNING OBJECTIVES:\n",
    "- Understand Hail MatrixTable structure for genomic data\n",
    "- Learn how to query specific genetic variants\n",
    "- Extract participant genotypes across multiple variants\n",
    "- Create analysis-ready genotype matrices\n",
    "\n",
    "## OUTPUT FORMAT:\n",
    "The function returns a Polars DataFrame with structure:\n",
    "- **Columns**: person_id, chr#:pos:ref:alt (one column per variant)\n",
    "- **Values**: \"0/0\", \"0/1\", \"1/1\", or null (missing)\n",
    "- **Example**:\n",
    "  ```\n",
    "  person_id | 19:39248514:TT:G | 19:39247938:G:A\n",
    "  ----------|------------------|------------------\n",
    "  1000001   | 0/0              | 0/1\n",
    "  1000002   | 0/1              | 0/0\n",
    "  1000003   | 1/1              | null\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 1: IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from itertools import combinations\n",
    "\n",
    "# Hail will be imported later (after we set up paths)\n",
    "# import hail as hl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 2: UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polars_gbq(query: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Execute a SQL query on Google BigQuery and return result as Polars DataFrame.\n",
    "\n",
    "    This is our standard method for querying the All of Us OMOP CDM database.\n",
    "    Polars is preferred over pandas for better performance with large datasets.\n",
    "\n",
    "    :param query: BigQuery SQL query string (can be multi-line)\n",
    "    :type query: str\n",
    "    :return: Query results as Polars DataFrame\n",
    "    :rtype: pl.DataFrame\n",
    "\n",
    "    \"\"\"\n",
    "    rows = bigquery.Client().query(query).result()\n",
    "    df = pl.from_arrow(rows.to_arrow())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_to_polars(spark_df) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert Spark DataFrame to Polars DataFrame.\n",
    "\n",
    "    WHY THIS IS NEEDED:\n",
    "    - Hail (genomics framework) uses Apache Spark under the hood\n",
    "    - Hail's .to_spark() method exports data as Spark DataFrames\n",
    "    - We convert to Polars for easier analysis and better performance\n",
    "\n",
    "    HOW IT WORKS:\n",
    "    1. Converts Spark DataFrame to Apache Arrow format (columnar data structure)\n",
    "    2. Converts Arrow to Polars DataFrame\n",
    "    \"\"\"\n",
    "    import pyarrow as pa\n",
    "\n",
    "    polars_df = pl.from_arrow(pa.Table.from_batches(spark_df._collect_as_arrow()))\n",
    "    return polars_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 3: BIGQUERY SQL QUERIES FOR CLINICAL DATA\n",
    "\n",
    "These functions generate SQL queries to extract clinical and demographic data from the All of Us OMOP CDM database.\n",
    "\n",
    "**OMOP TABLES USED:**\n",
    "- person: Demographics (birth date, sex)\n",
    "- death: Death dates (if applicable)\n",
    "- condition_occurrence: Diagnosis codes\n",
    "- observation: Additional diagnosis codes\n",
    "- concept: Code definitions and vocabularies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_age_query(ds: str, participant_ids: tuple) -> str:\n",
    "    \"\"\"\n",
    "    Generate SQL query to calculate participant ages.\n",
    "\n",
    "    WHAT IT CALCULATES:\n",
    "    - Date of birth\n",
    "    - Year of birth\n",
    "    - Current age (or age at death if deceased)\n",
    "    - Age squared (for polynomial regression models)\n",
    "    - Age cubed (for polynomial regression models)\n",
    "\n",
    "    HOW IT WORKS:\n",
    "    1. Joins person table with death table (left join, so NULL if alive)\n",
    "    2. Uses death date if available, otherwise current date\n",
    "    3. Calculates age in years (accounting for leap years: 365.2425 days/year)\n",
    "    4. Computes polynomial terms for flexible age modeling\n",
    "\n",
    "    :param ds: Google BigQuery dataset ID containing OMOP data tables\n",
    "    :type ds: str\n",
    "    :param participant_ids: Tuple of participant IDs to query\n",
    "    :type participant_ids: tuple\n",
    "    :return: SQL query string\n",
    "    :rtype: str\n",
    "\n",
    "    EXAMPLE:\n",
    "        participant_ids = (1000001, 1000002, 1000003)\n",
    "        query = current_age_query(WORKSPACE_CDR, participant_ids)\n",
    "        age_df = polars_gbq(query)\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            DISTINCT p.person_id,\n",
    "            EXTRACT(DATE FROM DATETIME(birth_datetime)) AS date_of_birth,\n",
    "            EXTRACT(YEAR FROM DATETIME(birth_datetime)) AS year_of_birth,\n",
    "            DATETIME_DIFF(\n",
    "                IF(DATETIME(death_datetime) IS NULL, CURRENT_DATETIME(), DATETIME(death_datetime)),\n",
    "                DATETIME(birth_datetime),\n",
    "                DAY\n",
    "            )/365.2425 AS current_age,\n",
    "            POW(DATETIME_DIFF(\n",
    "                IF(DATETIME(death_datetime) IS NULL, CURRENT_DATETIME(), DATETIME(death_datetime)),\n",
    "                DATETIME(birth_datetime),\n",
    "                DAY\n",
    "            )/365.2425, 2) AS current_age_squared,\n",
    "            POW(DATETIME_DIFF(\n",
    "                IF(DATETIME(death_datetime) IS NULL, CURRENT_DATETIME(), DATETIME(death_datetime)),\n",
    "                DATETIME(birth_datetime),\n",
    "                DAY\n",
    "            )/365.2425, 3) AS current_age_cubed\n",
    "        FROM\n",
    "            {ds}.person AS p\n",
    "        LEFT JOIN\n",
    "            {ds}.death AS d\n",
    "        ON\n",
    "            p.person_id = d.person_id\n",
    "        WHERE\n",
    "            p.person_id IN {participant_ids}\n",
    "    \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ehr_dx_code_query(ds: str, participant_ids: tuple) -> str:\n",
    "    \"\"\"\n",
    "    Generate SQL query to calculate EHR utilization metrics.\n",
    "\n",
    "    WHAT IT CALCULATES:\n",
    "    - Last EHR date: Most recent diagnosis code entry\n",
    "    - EHR length: Years from first to last diagnosis code (measure of data span)\n",
    "    - Dx code occurrence count: Total number of diagnosis codes recorded\n",
    "    - Dx condition count: Number of unique diagnosis codes\n",
    "    - Age at last EHR event: Age at most recent diagnosis\n",
    "\n",
    "    WHY THIS IS USEFUL:\n",
    "    - Controls for healthcare utilization bias in analyses\n",
    "    - Participants with more EHR data have more opportunities for diagnoses\n",
    "    - Common covariates in epidemiological studies\n",
    "\n",
    "    DATA SOURCES:\n",
    "    - Condition_occurrence table (primary source for diagnosis codes)\n",
    "    - Observation table (supplementary diagnosis codes)\n",
    "    - Both ICD9CM and ICD10CM vocabularies\n",
    "\n",
    "    HOW IT WORKS:\n",
    "    1. Unions 4 queries to capture all diagnosis codes:\n",
    "       - condition_occurrence.condition_source_value (direct code match)\n",
    "       - condition_occurrence.condition_source_concept_id (concept ID match)\n",
    "       - observation.observation_source_value (direct code match)\n",
    "       - observation.observation_source_concept_id (concept ID match)\n",
    "    2. Joins with person table to get birth dates\n",
    "    3. Calculates summary statistics per person\n",
    "\n",
    "    :param ds: Google BigQuery dataset ID containing OMOP data tables\n",
    "    :type ds: str\n",
    "    :param participant_ids: Tuple of participant IDs to query\n",
    "    :type participant_ids: tuple\n",
    "    :return: SQL query string\n",
    "    :rtype: str\n",
    "\n",
    "    EXAMPLE:\n",
    "        participant_ids = (1000001, 1000002, 1000003)\n",
    "        query = ehr_dx_code_query(WORKSPACE_CDR, participant_ids)\n",
    "        ehr_df = polars_gbq(query)\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT DISTINCT\n",
    "            df1.person_id,\n",
    "            MAX(date) AS last_ehr_date,\n",
    "            (DATETIME_DIFF(MAX(date), MIN(date), DAY) + 1)/365.2425 AS ehr_length,\n",
    "            COUNT(code) AS dx_code_occurrence_count,\n",
    "            COUNT(DISTINCT(code)) AS dx_condition_count,\n",
    "            DATETIME_DIFF(MAX(date), MIN(birthday), DAY)/365.2425 AS age_at_last_ehr_event,\n",
    "            POW(DATETIME_DIFF(MAX(date), MIN(birthday), DAY)/365.2425, 2) AS age_at_last_ehr_event_squared,\n",
    "            POW(DATETIME_DIFF(MAX(date), MIN(birthday), DAY)/365.2425, 3) AS age_at_last_ehr_event_cubed\n",
    "        FROM\n",
    "            (\n",
    "                -- Query 1: condition_occurrence with direct code match\n",
    "                (\n",
    "                SELECT DISTINCT\n",
    "                    co.person_id,\n",
    "                    co.condition_start_date AS date,\n",
    "                    c.concept_code AS code\n",
    "                FROM\n",
    "                    {ds}.condition_occurrence AS co\n",
    "                INNER JOIN\n",
    "                    {ds}.concept AS c\n",
    "                ON\n",
    "                    co.condition_source_value = c.concept_code\n",
    "                WHERE\n",
    "                    c.vocabulary_id IN (\"ICD9CM\", \"ICD10CM\")\n",
    "                    AND\n",
    "                    person_id IN {participant_ids}\n",
    "                )\n",
    "            UNION DISTINCT\n",
    "                -- Query 2: condition_occurrence with concept ID match\n",
    "                (\n",
    "                SELECT DISTINCT\n",
    "                    co.person_id,\n",
    "                    co.condition_start_date AS date,\n",
    "                    c.concept_code AS code\n",
    "                FROM\n",
    "                    {ds}.condition_occurrence AS co\n",
    "                INNER JOIN\n",
    "                    {ds}.concept AS c\n",
    "                ON\n",
    "                    co.condition_source_concept_id = c.concept_id\n",
    "                WHERE\n",
    "                    c.vocabulary_id IN (\"ICD9CM\", \"ICD10CM\")\n",
    "                    AND\n",
    "                    person_id IN {participant_ids}\n",
    "                )\n",
    "            UNION DISTINCT\n",
    "                -- Query 3: observation with direct code match\n",
    "                (\n",
    "                SELECT DISTINCT\n",
    "                    o.person_id,\n",
    "                    o.observation_date AS date,\n",
    "                    c.concept_code AS code\n",
    "                FROM\n",
    "                    {ds}.observation AS o\n",
    "                INNER JOIN\n",
    "                    {ds}.concept AS c\n",
    "                ON\n",
    "                    o.observation_source_value = c.concept_code\n",
    "                WHERE\n",
    "                    c.vocabulary_id IN (\"ICD9CM\", \"ICD10CM\")\n",
    "                    AND\n",
    "                    person_id IN {participant_ids}\n",
    "                )\n",
    "            UNION DISTINCT\n",
    "                -- Query 4: observation with concept ID match\n",
    "                (\n",
    "                SELECT DISTINCT\n",
    "                    o.person_id,\n",
    "                    o.observation_date AS date,\n",
    "                    c.concept_code AS code\n",
    "                FROM\n",
    "                    {ds}.observation AS o\n",
    "                INNER JOIN\n",
    "                    {ds}.concept AS c\n",
    "                ON\n",
    "                    o.observation_source_concept_id = c.concept_id\n",
    "                WHERE\n",
    "                    c.vocabulary_id IN (\"ICD9CM\", \"ICD10CM\")\n",
    "                    AND\n",
    "                    person_id IN {participant_ids}\n",
    "                )\n",
    "            ) AS df1\n",
    "        INNER JOIN\n",
    "            (\n",
    "                SELECT\n",
    "                    person_id,\n",
    "                    EXTRACT(DATE FROM DATETIME(birth_datetime)) AS birthday\n",
    "                FROM\n",
    "                    {ds}.person\n",
    "                WHERE\n",
    "                    person_id IN {participant_ids}\n",
    "            ) AS df2\n",
    "        ON\n",
    "            df1.person_id = df2.person_id\n",
    "        GROUP BY\n",
    "            df1.person_id\n",
    "    \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sex_at_birth_query(ds: str, participant_ids: tuple) -> str:\n",
    "    \"\"\"\n",
    "    Generate SQL query to extract sex at birth.\n",
    "\n",
    "    ENCODING:\n",
    "    - Male = 1\n",
    "    - Female = 0\n",
    "\n",
    "    DATA SOURCE:\n",
    "    - Uses sex_at_birth_source_concept_id from person table\n",
    "    - Concept ID 1585846 = Male\n",
    "    - Concept ID 1585847 = Female\n",
    "\n",
    "    NOTE:\n",
    "    - This is self-reported sex at birth from surveys\n",
    "    - For genetics analyses, you may also want to use genomic sex (from ploidy)\n",
    "\n",
    "    :param ds: Google BigQuery dataset ID containing OMOP data tables\n",
    "    :type ds: str\n",
    "    :param participant_ids: Tuple of participant IDs to query\n",
    "    :type participant_ids: tuple\n",
    "    :return: SQL query string\n",
    "    :rtype: str\n",
    "\n",
    "    EXAMPLE:\n",
    "        participant_ids = (1000001, 1000002, 1000003)\n",
    "        query = sex_at_birth_query(WORKSPACE_CDR, participant_ids)\n",
    "        sex_df = polars_gbq(query)\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            (\n",
    "                -- Male participants\n",
    "                (\n",
    "                SELECT\n",
    "                    person_id,\n",
    "                    1 AS sex_at_birth\n",
    "                FROM\n",
    "                    {ds}.person\n",
    "                WHERE\n",
    "                    sex_at_birth_source_concept_id = 1585846\n",
    "                AND\n",
    "                    person_id IN {participant_ids}\n",
    "                )\n",
    "            UNION DISTINCT\n",
    "                -- Female participants\n",
    "                (\n",
    "                SELECT\n",
    "                    person_id,\n",
    "                    0 AS sex_at_birth\n",
    "                FROM\n",
    "                    {ds}.person\n",
    "                WHERE\n",
    "                    sex_at_birth_source_concept_id = 1585847\n",
    "                AND\n",
    "                    person_id IN {participant_ids}\n",
    "                )\n",
    "            )\n",
    "    \"\"\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 4: CONFIGURATION AND PATHS\n",
    "\n",
    "Set up paths to genomic data and database connections.\n",
    "\n",
    "**IMPORTANT:** You must run `_reference/verily/00_setup_workspace.ipynb` first!\n",
    "\n",
    "That notebook sets up the WORKSPACE_CDR and WORKSPACE_BUCKET environment variables that are needed for all All of Us analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get workspace environment variables\n",
    "WORKSPACE_CDR = os.environ.get('WORKSPACE_CDR')\n",
    "WORKSPACE_BUCKET = os.environ.get('WORKSPACE_BUCKET')\n",
    "GOOGLE_PROJECT = os.environ.get('GOOGLE_PROJECT')\n",
    "\n",
    "# Validate environment setup\n",
    "if WORKSPACE_CDR is None:\n",
    "    print(\"ERROR: WORKSPACE_CDR not set!\")\n",
    "    print(\"Please run _reference/verily/00_setup_workspace.ipynb first\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(f\"Workspace CDR: {WORKSPACE_CDR}\")\n",
    "print(f\"Workspace Bucket: {WORKSPACE_BUCKET}\")\n",
    "print(f\"Google Project: {GOOGLE_PROJECT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GENOMIC DATA PATHS\n",
    "\n",
    "These paths point to the All of Us genomic data in Google Cloud Storage.\n",
    "\n",
    "**cdr8_mt_path:**\n",
    "- Hail MatrixTable (.mt) containing all genotype data for CDR v8\n",
    "- Contains ~245,000 participants with whole genome sequencing\n",
    "- Format: Hail MatrixTable (requires Hail to read)\n",
    "- Location: Controlled-tier All of Us dataset\n",
    "\n",
    "**ancestry_pred_path:**\n",
    "- TSV file with predicted genetic ancestry for each participant\n",
    "- Includes ancestry labels (EUR, AFR, AMR, EAS, SAS)\n",
    "- Includes first 16 principal components (PCs) from ancestry PCA\n",
    "- Used for ancestry stratification in GWAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of Us CDR v8 genomic data (Hail MatrixTable)\n",
    "cdr8_mt_path = \"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/splitMT/hail.mt\"\n",
    "\n",
    "# Ancestry predictions - SET THIS TO YOUR ANCESTRY FILE PATH\n",
    "# The user should provide this path\n",
    "ancestry_pred_path = \"YOUR_ANCESTRY_PREDICTIONS_PATH_HERE\"\n",
    "# Example: ancestry_pred_path = f\"{WORKSPACE_BUCKET}/data/ancestry_predictions.tsv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 5: GENOTYPE EXTRACTION\n",
    "\n",
    "This is the main workflow for extracting genotypes across all participants.\n",
    "\n",
    "## STEPS:\n",
    "1. Define variant(s) of interest (chromosome, position, alleles)\n",
    "2. Initialize Hail and load genomic data\n",
    "3. For each variant:\n",
    "   - Filter to variant of interest\n",
    "   - Extract genotypes for all participants\n",
    "   - Format genotypes as strings (0/0, 0/1, 1/1)\n",
    "4. Merge all variants into a single DataFrame\n",
    "5. Save genotype matrix file\n",
    "\n",
    "## OUTPUT:\n",
    "A wide-format DataFrame where:\n",
    "- Rows = participants (person_id)\n",
    "- Columns = variants (chr:pos:ref:alt)\n",
    "- Values = genotypes (\"0/0\", \"0/1\", \"1/1\", or null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genotypes_for_variants(\n",
    "    variant_list: list,\n",
    "    reference_genome: str = \"GRCh38\",\n",
    "    output_file_path: str = None\n",
    ") -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract genotypes for all participants across multiple specified variants.\n",
    "\n",
    "    PARAMETERS:\n",
    "    -----------\n",
    "    variant_list : list of dict\n",
    "        List of variants to query. Each variant is a dictionary with keys:\n",
    "        - 'chromosome': int (chromosome number, 1-22, or 23 for X, 24 for Y)\n",
    "        - 'position': int (genomic position in base pairs)\n",
    "        - 'ref': str (reference allele)\n",
    "        - 'alt': str (alternative allele)\n",
    "\n",
    "        Example:\n",
    "        [\n",
    "            {'chromosome': 19, 'position': 39248514, 'ref': 'TT', 'alt': 'G'},\n",
    "            {'chromosome': 19, 'position': 39247938, 'ref': 'G', 'alt': 'A'}\n",
    "        ]\n",
    "\n",
    "    reference_genome : str\n",
    "        Reference genome version (\"GRCh37\" or \"GRCh38\")\n",
    "        All of Us uses GRCh38 by default\n",
    "\n",
    "    output_file_path : str\n",
    "        Path to save cohort TSV file\n",
    "        If None, will create default filename\n",
    "\n",
    "    RETURNS:\n",
    "    --------\n",
    "    pl.DataFrame\n",
    "        DataFrame with columns:\n",
    "        - person_id: participant ID\n",
    "        - One column per variant with name format \"chr#:pos:ref:alt\"\n",
    "        - Each variant column contains genotype strings: \"0/0\", \"0/1\", \"1/1\", or null\n",
    "\n",
    "    EXAMPLE:\n",
    "    --------\n",
    "    # Extract genotypes for two variants\n",
    "    variants = [\n",
    "        {'chromosome': 19, 'position': 39248514, 'ref': 'TT', 'alt': 'G'},\n",
    "        {'chromosome': 19, 'position': 39247938, 'ref': 'G', 'alt': 'A'}\n",
    "    ]\n",
    "    \n",
    "    genotype_df = extract_genotypes_for_variants(\n",
    "        variant_list=variants,\n",
    "        output_file_path=\"genotypes.tsv\"\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 1: VALIDATE INPUTS\n",
    "    # ========================================================================\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENOTYPE EXTRACTION FOR MULTIPLE VARIANTS\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    if not variant_list or len(variant_list) == 0:\n",
    "        print(\"‚ùå ERROR: variant_list is empty. Please provide at least one variant.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"\\nüìç Extracting genotypes for {len(variant_list)} variant(s):\")\n",
    "    for i, var in enumerate(variant_list, 1):\n",
    "        print(f\"   {i}. chr{var['chromosome']}:{var['position']}:{var['ref']}:{var['alt']}\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 2: INITIALIZE HAIL\n",
    "    # ========================================================================\n",
    "\n",
    "    import hail as hl\n",
    "\n",
    "    print(\"\\n‚öôÔ∏è  Initializing Hail...\")\n",
    "    try:\n",
    "        hl.init(default_reference=reference_genome)\n",
    "        print(\"‚úì Hail initialized successfully\")\n",
    "    except Exception as err:\n",
    "        if \"IllegalArgumentException\" not in str(err):\n",
    "            raise\n",
    "        else:\n",
    "            print(\"‚úì Hail already initialized (skipping)\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 3: LOAD GENOMIC DATA\n",
    "    # ========================================================================\n",
    "\n",
    "    print(f\"\\nüìÇ Loading genomic data from:\")\n",
    "    print(f\"   {cdr8_mt_path}\")\n",
    "\n",
    "    mt = hl.read_matrix_table(cdr8_mt_path)\n",
    "    print(f\"‚úì MatrixTable loaded\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 4: PROCESS EACH VARIANT\n",
    "    # ========================================================================\n",
    "\n",
    "    all_genotype_dfs = []\n",
    "\n",
    "    for var_idx, var in enumerate(variant_list, 1):\n",
    "        chromosome_number = var['chromosome']\n",
    "        genomic_position = var['position']\n",
    "        ref_allele = var['ref']\n",
    "        alt_allele = var['alt']\n",
    "\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"PROCESSING VARIANT {var_idx}/{len(variant_list)}\")\n",
    "        print(f\"{'='*70}\")\n",
    "\n",
    "        # Construct variant string\n",
    "        alleles = f\"{ref_allele}:{alt_allele}\"\n",
    "        base_locus = f\"{chromosome_number}:{genomic_position}\"\n",
    "\n",
    "        if reference_genome == \"GRCh38\":\n",
    "            locus = \"chr\" + base_locus\n",
    "        elif reference_genome == \"GRCh37\":\n",
    "            locus = base_locus\n",
    "        else:\n",
    "            print(\"‚ùå Invalid reference version. Allowed inputs are 'GRCh37' or 'GRCh38'.\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        variant_string = locus + \":\" + alleles\n",
    "        variant_col_name = f\"{base_locus}:{ref_allele}:{alt_allele}\"\n",
    "        \n",
    "        print(f\"\\nüîç Searching for variant: {variant_string}\")\n",
    "        print(f\"   Column name: {variant_col_name}\")\n",
    "\n",
    "        # Parse variant\n",
    "        variant = hl.parse_variant(variant_string, reference_genome=reference_genome)\n",
    "\n",
    "        # Filter to locus\n",
    "        mt_variant = mt.filter_rows(mt.locus == hl.Locus.parse(locus))\n",
    "\n",
    "        n_variants_at_locus = mt_variant.count_rows()\n",
    "        if n_variants_at_locus == 0:\n",
    "            print(f\"‚ùå WARNING: Locus {locus} not found in dataset!\")\n",
    "            print(f\"   This variant will be skipped.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"‚úì Found {n_variants_at_locus} variant(s) at locus {locus}\")\n",
    "\n",
    "        # Handle multi-allelic sites\n",
    "        allele_count_df = spark_to_polars(mt_variant.entries().select(\"info\").to_spark())\n",
    "\n",
    "        if len(allele_count_df) > 0 and allele_count_df[\"info.AF\"][0] is not None:\n",
    "            allele_count = len(allele_count_df[\"info.AF\"][0])\n",
    "\n",
    "            if allele_count > 1:\n",
    "                print(f\"\\n‚ö†Ô∏è  Multi-allelic site detected ({allele_count} alt alleles)\")\n",
    "                print(\"   Splitting multi-allelic variants...\")\n",
    "                mt_variant = hl.split_multi_hts(mt_variant)\n",
    "                print(\"‚úì Split complete\")\n",
    "\n",
    "        # Filter to exact variant\n",
    "        print(f\"\\nüéØ Filtering to exact variant: {variant_string}\")\n",
    "        mt_variant = mt_variant.filter_rows(\n",
    "            (mt_variant.locus == variant[\"locus\"]) &\n",
    "            (mt_variant.alleles == variant[\"alleles\"])\n",
    "        )\n",
    "\n",
    "        n_variants = mt_variant.count_rows()\n",
    "        if n_variants == 0:\n",
    "            print(f\"‚ùå WARNING: Variant {variant_string} not found!\")\n",
    "            print(f\"   This variant will be skipped.\")\n",
    "            continue\n",
    "        else:\n",
    "            print(f\"‚úì Variant {variant_string} found!\")\n",
    "\n",
    "        # Extract genotypes\n",
    "        print(\"\\nüìä Extracting genotypes for all participants...\")\n",
    "\n",
    "        spark_df = mt_variant.entries().select(\"GT\").to_spark()\n",
    "        polars_df = spark_to_polars(spark_df)\n",
    "\n",
    "        print(f\"‚úì Extracted genotypes for {len(polars_df):,} participants\")\n",
    "\n",
    "        # Format genotypes\n",
    "        print(\"\\nüîÑ Converting genotype format...\")\n",
    "\n",
    "        polars_df = polars_df.with_columns(\n",
    "            pl.col(\"GT.alleles\").list.get(0).cast(pl.Utf8).alias(\"GT0\"),\n",
    "            pl.col(\"GT.alleles\").list.get(1).cast(pl.Utf8).alias(\"GT1\"),\n",
    "        )\n",
    "\n",
    "        polars_df = polars_df.with_columns(\n",
    "            (pl.col(\"GT0\") + \"/\" + pl.col(\"GT1\")).alias(variant_col_name)\n",
    "        )\n",
    "\n",
    "        # Rename 's' to 'person_id'\n",
    "        polars_df = polars_df.rename({\"s\": \"person_id\"})\n",
    "        polars_df = polars_df.with_columns(pl.col(\"person_id\").cast(int))\n",
    "\n",
    "        # Select only person_id and genotype column\n",
    "        polars_df = polars_df.select([\"person_id\", variant_col_name])\n",
    "\n",
    "        print(\"‚úì Genotypes formatted\")\n",
    "\n",
    "        # Show genotype distribution\n",
    "        print(f\"\\nüìà Genotype distribution for {variant_col_name}:\")\n",
    "        gt_counts = polars_df.group_by(variant_col_name).agg(\n",
    "            pl.count().alias(\"count\")\n",
    "        ).sort(\"count\", descending=True)\n",
    "        \n",
    "        for row in gt_counts.iter_rows(named=True):\n",
    "            count = row['count']\n",
    "            gt = row[variant_col_name]\n",
    "            if count < 20:\n",
    "                print(f\"   {gt}: <20 participants\")\n",
    "            else:\n",
    "                print(f\"   {gt}: {count:,} participants\")\n",
    "\n",
    "        all_genotype_dfs.append(polars_df)\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 5: MERGE ALL VARIANTS\n",
    "    # ========================================================================\n",
    "\n",
    "    if len(all_genotype_dfs) == 0:\n",
    "        print(\"\\n‚ùå ERROR: No variants were successfully extracted!\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"MERGING VARIANTS\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Start with first variant\n",
    "    merged_df = all_genotype_dfs[0]\n",
    "    print(f\"\\n‚úì Starting with {len(merged_df):,} participants from variant 1\")\n",
    "\n",
    "    # Join remaining variants\n",
    "    for i, df in enumerate(all_genotype_dfs[1:], 2):\n",
    "        print(f\"\\nüîó Joining variant {i}...\")\n",
    "        merged_df = merged_df.join(df, on=\"person_id\", how=\"outer\")\n",
    "        print(f\"   ‚úì Now have {len(merged_df):,} participants total\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # STEP 6: SAVE AND SUMMARIZE\n",
    "    # ========================================================================\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"FINAL GENOTYPE MATRIX SUMMARY\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Total participants: {len(merged_df):,}\")\n",
    "    print(f\"‚úÖ Total variants: {len(merged_df.columns) - 1}\")\n",
    "    print(f\"\\nüìã Columns: {', '.join(merged_df.columns)}\")\n",
    "\n",
    "    # Count participants with data for all variants\n",
    "    non_null_counts = merged_df.select(\n",
    "        [pl.col(c).is_not_null().sum().alias(c) for c in merged_df.columns if c != \"person_id\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nüìä Participants with genotype data per variant:\")\n",
    "    for col in merged_df.columns:\n",
    "        if col != \"person_id\":\n",
    "            count = merged_df.filter(pl.col(col).is_not_null()).shape[0]\n",
    "            print(f\"   {col}: {count:,}\")\n",
    "\n",
    "    # Set default output filename\n",
    "    if output_file_path is None:\n",
    "        output_file_path = \"genotype_matrix.tsv\"\n",
    "\n",
    "    # Save to file\n",
    "    merged_df.write_csv(output_file_path, separator=\"\\t\")\n",
    "    print(f\"\\nüíæ Genotype matrix saved to: {output_file_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 6: EXAMPLE USAGE\n",
    "\n",
    "This section demonstrates how to use the extract_genotypes_for_variants() function.\n",
    "\n",
    "**EXAMPLE 1: Single variant**\n",
    "Extract genotypes for one variant across all participants.\n",
    "\n",
    "**EXAMPLE 2: Multiple variants**\n",
    "Extract genotypes for multiple variants simultaneously.\n",
    "The function will create a wide-format DataFrame with one column per variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXAMPLE 1: Single variant - GPR15 rs28688207\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nExtracting genotypes for one variant associated with IBD\")\n",
    "print(\"Reference: chr2:233,269,839 C>T (GRCh38)\")\n",
    "\n",
    "# Define single variant\n",
    "variants_single = [\n",
    "    {\n",
    "        'chromosome': 2,\n",
    "        'position': 233269839,\n",
    "        'ref': 'C',\n",
    "        'alt': 'T'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Extract genotypes\n",
    "genotypes_single = extract_genotypes_for_variants(\n",
    "    variant_list=variants_single,\n",
    "    reference_genome=\"GRCh38\",\n",
    "    output_file_path=\"gpr15_genotypes.tsv\"\n",
    ")\n",
    "\n",
    "if genotypes_single is not None:\n",
    "    print(\"\\nFirst 10 rows:\")\n",
    "    print(genotypes_single.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXAMPLE 2: Multiple variants - Custom variant list\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nExtracting genotypes for multiple variants simultaneously\")\n",
    "\n",
    "# Define multiple variants\n",
    "# User can specify any variants they want to analyze\n",
    "variants_multiple = [\n",
    "    {\n",
    "        'chromosome': 19,\n",
    "        'position': 39248514,\n",
    "        'ref': 'TT',\n",
    "        'alt': 'G'\n",
    "    },\n",
    "    {\n",
    "        'chromosome': 19,\n",
    "        'position': 39247938,\n",
    "        'ref': 'G',\n",
    "        'alt': 'A'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Extract genotypes for all variants\n",
    "genotypes_multiple = extract_genotypes_for_variants(\n",
    "    variant_list=variants_multiple,\n",
    "    reference_genome=\"GRCh38\",\n",
    "    output_file_path=\"multi_variant_genotypes.tsv\"\n",
    ")\n",
    "\n",
    "if genotypes_multiple is not None:\n",
    "    print(\"\\nFirst 10 rows of multi-variant matrix:\")\n",
    "    print(genotypes_multiple.head(10))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"GENOTYPE MATRIX STRUCTURE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nThe output DataFrame has:\")\n",
    "    print(f\"  - {len(genotypes_multiple):,} participants (rows)\")\n",
    "    print(f\"  - {len(genotypes_multiple.columns) - 1} variant(s) (columns)\")\n",
    "    print(f\"  - Columns: {', '.join(genotypes_multiple.columns)}\")\n",
    "    print(\"\\nEach variant column contains genotypes:\")\n",
    "    print(\"  - '0/0' = homozygous reference\")\n",
    "    print(\"  - '0/1' = heterozygous\")\n",
    "    print(\"  - '1/1' = homozygous alternative\")\n",
    "    print(\"  - null = missing genotype data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SECTION 7: OPTIONAL - ADDING CLINICAL DATA\n",
    "\n",
    "After creating the genotype matrix, you may want to add:\n",
    "- Demographics (age, sex)\n",
    "- Clinical data (EHR length, diagnosis counts)\n",
    "- Ancestry information (genetic ancestry, PCs)\n",
    "\n",
    "This section shows how to use the SQL query functions to retrieve this data and join it with your genotype matrix.\n",
    "\n",
    "**Use case**: Combine genotype data with phenotype data for association analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clinical_data_example(genotype_df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Example function showing how to add clinical data to a genotype matrix.\n",
    "\n",
    "    This is for educational purposes - shows the workflow step-by-step.\n",
    "\n",
    "    :param genotype_df: Genotype matrix with person_id column and variant columns\n",
    "    :return: Enhanced genotype matrix with clinical data\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ADDING CLINICAL DATA TO GENOTYPE MATRIX\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Get list of participant IDs\n",
    "    participant_ids = tuple(genotype_df[\"person_id\"].unique().to_list())\n",
    "    print(f\"\\nüìã Adding data for {len(participant_ids):,} participants\")\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # AGE DATA\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n1Ô∏è‚É£  Retrieving age data...\")\n",
    "    age_query = current_age_query(WORKSPACE_CDR, participant_ids)\n",
    "    age_df = polars_gbq(age_query)\n",
    "    print(f\"   ‚úì Retrieved age data for {len(age_df):,} participants\")\n",
    "\n",
    "    # Join with genotype matrix\n",
    "    genotype_df = genotype_df.join(\n",
    "        age_df[[\"person_id\", \"current_age\", \"year_of_birth\"]],\n",
    "        how=\"left\",\n",
    "        on=\"person_id\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # SEX AT BIRTH\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n2Ô∏è‚É£  Retrieving sex at birth...\")\n",
    "    sex_query = sex_at_birth_query(WORKSPACE_CDR, participant_ids)\n",
    "    sex_df = polars_gbq(sex_query)\n",
    "    print(f\"   ‚úì Retrieved sex data for {len(sex_df):,} participants\")\n",
    "\n",
    "    # Join with genotype matrix\n",
    "    genotype_df = genotype_df.join(sex_df, how=\"left\", on=\"person_id\")\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # EHR UTILIZATION DATA\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n3Ô∏è‚É£  Retrieving EHR utilization data...\")\n",
    "    ehr_query = ehr_dx_code_query(WORKSPACE_CDR, participant_ids)\n",
    "    ehr_df = polars_gbq(ehr_query)\n",
    "    print(f\"   ‚úì Retrieved EHR data for {len(ehr_df):,} participants\")\n",
    "\n",
    "    # Join with genotype matrix\n",
    "    genotype_df = genotype_df.join(\n",
    "        ehr_df[[\"person_id\", \"ehr_length\", \"dx_code_occurrence_count\", \"age_at_last_ehr_event\"]],\n",
    "        how=\"left\",\n",
    "        on=\"person_id\"\n",
    "    )\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "    # SUMMARY\n",
    "    # ------------------------------------------------------------------------\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ENHANCED GENOTYPE MATRIX SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    print(f\"\\nüìä Matrix size: {len(genotype_df):,} participants\")\n",
    "    print(f\"\\nüìã Columns: {', '.join(genotype_df.columns)}\")\n",
    "    \n",
    "    # Separate genotype columns from clinical columns\n",
    "    genotype_cols = [c for c in genotype_df.columns if ':' in c]\n",
    "    clinical_cols = [c for c in genotype_df.columns if c not in genotype_cols and c != 'person_id']\n",
    "    \n",
    "    print(f\"\\nüß¨ Genotype columns ({len(genotype_cols)}): {', '.join(genotype_cols)}\")\n",
    "    print(f\"üè• Clinical columns ({len(clinical_cols)}): {', '.join(clinical_cols)}\")\n",
    "\n",
    "    print(\"\\nüìà Summary statistics (clinical data):\")\n",
    "    if clinical_cols:\n",
    "        print(genotype_df.select(clinical_cols).describe())\n",
    "\n",
    "    # Save enhanced genotype matrix\n",
    "    output_path = \"enhanced_genotype_matrix.tsv\"\n",
    "    genotype_df.write_csv(output_path, separator=\"\\t\")\n",
    "    print(f\"\\nüíæ Enhanced genotype matrix saved to: {output_path}\")\n",
    "\n",
    "    return genotype_df\n",
    "\n",
    "\n",
    "# Example usage of clinical data addition:\n",
    "# if genotypes_multiple is not None:\n",
    "#     enhanced_genotype_matrix = add_clinical_data_example(genotypes_multiple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF EDUCATIONAL WORKFLOW\n",
    "\n",
    "## NEXT STEPS:\n",
    "1. Modify the variant_list for your own variants of interest\n",
    "2. Add clinical/demographic data as needed (see Section 7 for examples)\n",
    "3. Perform downstream analyses:\n",
    "   - Association testing (compare genotypes across phenotypes)\n",
    "   - PheWAS (phenome-wide association studies)\n",
    "   - Stratification analysis\n",
    "   - Visualization (genotype distributions, allele frequencies)\n",
    "\n",
    "## USING YOUR GENOTYPE MATRIX:\n",
    "The extracted genotype matrix can be used for many analyses:\n",
    "\n",
    "**Example 1: Filter to specific genotypes**\n",
    "```python\n",
    "# Get participants with heterozygous genotype at first variant\n",
    "het_carriers = genotype_df.filter(\n",
    "    pl.col(\"19:39248514:TT:G\") == \"0/1\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Example 2: Count genotypes**\n",
    "```python\n",
    "# Count each genotype for a variant\n",
    "genotype_df.group_by(\"19:39248514:TT:G\").agg(pl.count())\n",
    "```\n",
    "\n",
    "**Example 3: Compound genotype analysis**\n",
    "```python\n",
    "# Find participants with specific genotype combinations\n",
    "compound = genotype_df.filter(\n",
    "    (pl.col(\"19:39248514:TT:G\") == \"0/1\") &\n",
    "    (pl.col(\"19:39247938:G:A\") == \"1/1\")\n",
    ")\n",
    "```\n",
    "\n",
    "## RESOURCES:\n",
    "- Hail documentation: https://hail.is/docs/0.2/\n",
    "- All of Us Data Browser: https://databrowser.researchallofus.org/\n",
    "- OMOP CDM documentation: https://ohdsi.github.io/CommonDataModel/\n",
    "\n",
    "## TROUBLESHOOTING:\n",
    "- \"Variant not found\": Check chromosome, position, ref/alt alleles match GRCh38\n",
    "- \"Hail initialization error\": Restart kernel and try again\n",
    "- \"Out of memory\": Use fewer variants or request larger machine\n",
    "- \"Multi-allelic warning\": This is normal - the function handles it automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
